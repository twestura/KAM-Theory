\documentclass{beamer}

\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bm}
\usepackage[shortlabels]{enumitem}
\usepackage{esvect}
\usepackage{lipsum}
\usepackage{listings}
\usepackage{mathtools}
\usepackage{marginnote}
\usepackage{subfiles}
\usepackage{import}
\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\usepackage[english]{babel}

\usetheme{Berlin}
\usecolortheme{beaver}

\setbeamercolor{structure}{fg=darkred}

\renewcommand{\qedsymbol}{\text{QED}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
%\newcommand{\e}{\mathrm{e}}
%\renewcommand{\i}{\mathrm{i}}
\renewcommand{\qedsymbol}{\text{QED}}

\DeclareMathOperator{\Real}{Re}
\DeclareMathOperator{\Imag}{Im}

\newcommand{\bp}[1]{\bm{#1}}
\newcommand{\bv}[1]{\vv{\bm{#1}}}
\newcommand{\bd}[1]{\bm{\dot{#1}}}
\newcommand{\bdd}[1]{\bm{\ddot{#1}}}
\newcommand{\grad}{\vv{\nabla}}
\newcommand{\sgrad}{\nabla_{\sigma}}

\newcommand{\genericdel}[4]{%
  \ifcase#3\relax
  #1#4#2\or
  \bigl#1#4\bigr#2\or
  \Bigl#1#4\Bigr#2\or
  \biggl#1#4\biggr#2\or
  \Biggl#1#4\Biggr#2\else
  \left#1#4\right#2\fi
}
\newcommand{\del}[2][-1]{\genericdel(){#1}{#2}}
\newcommand{\set}[2][-1]{\genericdel\{\}{#1}{#2}}
\let\cbr\set
\newcommand{\sbr}[2][-1]{\genericdel[]{#1}{#2}}
\let\intoo\del
\let\intcc\sbr
\newcommand{\intoc}[2][-1]{\genericdel(]{#1}{#2}}
\newcommand{\intco}[2][-1]{\genericdel[){#1}{#2}}
\newcommand{\eval}[2][-1]{\genericdel.|{#1}{#2}}
\newcommand{\envert}[2][-1]{\genericdel||{#1}{#2}}
\let\abs\envert
\newcommand{\sVert}[2][0]{%
  \ifcase#1\relax
  \rvert\or\bigr|\or\Bigr|\or\biggr|\or\Biggr
  \fi
}
\newcommand{\enVert}[2][-1]{\genericdel\|\|{#1}{#2}}
\let\norm\enVert

\newcommand{\dif}{\mathop{}\!{d}}
\newcommand{\Dif}{\mathop{}\!\mathrm{D}}

\newcommand\pd[3][]{\frac{\strut\partial^{#1}#2}{\strut\partial#3^{#1}}}
\newcommand\tpd[3][]{\tfrac{\partial^{#1}#2}{\partial#3^{#1}}}
\newcommand\dpd[3][]{\dfrac{\partial^{#1}#2}{\partial#3^{#1}}}

\newcommand{\md}[6]{\frac{\partial^{#2}#1}{\partial#3^{#4}\partial#5^{#6}}}
\newcommand{\tmd}[6]{\tfrac{\partial^{#2}#1}{\partial#3^{#4}\partial#5^{#6}}}
\newcommand{\dmd}[6]{\dfrac{\partial^{#2}#1}{\partial#3^{#4}\partial#5^{#6}}}

\newcommand{\od}[3][]{\frac{\dif^{#1}#2}{\dif#3^{#1}}}
\newcommand{\tod}[3][]{\tfrac{\dif^{#1}#2}{\dif#3^{#1}}}
\newcommand{\dod}[3][]{\dfrac{\dif^{#1}#2}{\dif#3^{#1}}}

\expandafter\def\expandafter\normalsize\expandafter{%
    \normalsize
    \setlength\abovedisplayskip{2pt}
    \setlength\belowdisplayskip{2pt}
    \setlength\abovedisplayshortskip{2pt}
    \setlength\belowdisplayshortskip{2pt}
}

\everymath{\displaystyle}

\input{mathmacros.tex}

\title[KAM]{Kolmogorov's Theorem}
\author{Travis Westura}
\institute{Cornell University}
\date{April 20, 2015}

\begin{document}

\frame{\titlepage}

\begin{frame}
  %\frametitle{Kolmogorov's Theorem}
  Our goal is to understand the following theorem.
  \newtheorem{kamthm}{Kolmogorov's Theorem}
  \begin{kamthm}
    \KAM
  \end{kamthm}
\end{frame}

\begin{frame}
  \frametitle{Kolmogorov's Theorem}
  The \textbf{KAM} theory is named after
  \begin{itemize}
    \item Andre{\"i} \textbf{K}olmogorov,
    \item Vladimir \textbf{A}rnold,
    \item J{\"u}rgen \textbf{M}oser.
  \end{itemize}
  Kolmogorov gave an original proof in the $1950$s but never published it.
  Arnold gave a proof of the theorem in $1963$ and Moser published a different
  but related result in $1962$.
\end{frame}

\begin{frame}
  \frametitle{A Motivating Example}
  % TODO
  The solar system when planets have zero mass.

  A system with $n$ masses $m_i$ and positions $\bp{x}_i$ satisfies Newton's
  $\bp{F} = m \bp{a}$ law:
  \begin{equation*}
    m_i \bdd{x}_i = \sum_{j \neq i} G m_i m_j \frac{\bp{x}_j -
      \bp{x}_i}{|\bp{x}_j - \bp{x}_i|^3}.
  \end{equation*}

  We take the sun to be given by index $0$ and the plants to be given by the
  indices $1, \ldots n$.
\end{frame}

\begin{frame}
  \frametitle{A Motivating Example}
  Take the sun to be at the center of the solar system ($\bp{x}_0 = 0$) and
  setting the masses of the planets to zero ($m_i = 0$ for $i \neq 0$).

  We obtain $\bp{x}_0'' = 0$ and for $i \neq 0$
  \begin{equation*}
    \bp{x}_i'' = -G m_0 \frac{\bp{x}_i}{|\bp{x}_i|^3}.
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  Named for William Rowan Hamilton ($1805$-$1865$).

  A reformulation of classical Newtonian mechanics.

  Relies on a symplectic structure.
\end{frame}

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  Let $(X, \sigma)$ be a symplectic manifold.
  That is, $X$ is a differentiable manifold and $\sigma$ is a nowhere vanishing
  $2$-form such that $\dif \sigma = 0$.

  A function $H$ on a $X$ has a \emph{symplectic gradient} denoted $\sgrad H$.
  This gradient is the unique vector field such that for any vector field $\xi$,
  we have
  \begin{equation*}
    \sigma(\xi, \sgrad H) = \dif H(\xi).
  \end{equation*}

  We will consider a \emph{Hamiltonian differential equation} that makes use of
  this symplectic gradient:
  \begin{equation*}
    \bd{x} = (\sgrad H)(\bp{x}).
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  Let's compare the symplectic gradient and the gradient $\nabla f$ of a function
  $f : \R^n \to \R$ from multivariable calculus.

  The gradient is the unique vector field such that
  \begin{equation*}
    df(\xi) = \langle \xi, \nabla f \rangle.
  \end{equation*}

  We could also consider the ``gradient differential equation''
  \begin{equation*}
    \bd{x} = \nabla f(\bp{x}).
  \end{equation*}

  Since $f$ increases along its solutions, they can never return to their
  starting point.

  This prohibits recurrence, whereas the Hamiltonian equations allow and almost
  impose recurrence (see the Poincar{\'e} recurrence theorem).
\end{frame}

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  For a simple example of a Hamiltonian system, consider $X = \R^{2n}$
  with coordinates $(q_1, \ldots, q_n, p_1, \ldots, p_n)$.
  Take $\sigma = \sum_i \dif p_i \wedge \dif q_i$.
  Our Hamiltonian differential equation is
  \begin{align*}
    \dot{q}_i &= \pd{H}{p_i},\\
    \dot{p}_i &= -\pd{H}{q_i},
  \end{align*}
  where these are called the \emph{Hamiltonian equations of motion}.
\end{frame}

% TODO how does this relate to the basic Hamiltonian system from 4200?

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  How does the Solar System fit this model?
  Consider the case of a single body of zero mass.
  (It is sufficient to consider the single body system, since the planets having
  zero mass means that they do not effect each other).
  For $\bp{x} \in \R^2$ the equation $\bdd{x} = -\frac{\bp{x}}{|\bp{x}|^3}$ is
  Hamilton's equation for the manifold $X = \R^2 \times \R^2$ with points
  $(\bp{q}, \bp{p})$, standard symplectic form
  \begin{equation*}
    \sigma = \dif p_1 \wedge \dif q_1 + \dif p_2 \wedge \dif q_2,
  \end{equation*}
  and Hamiltonian
  \begin{equation*}
    H(\bp{q}, \bp{p}) = \frac{1}{2} (p_1^2 + p_2^2) - \frac{1}{\sqrt{q_1^2 +
    q_2^2}}.
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  After some computation, we can obtain
  \begin{equation*}
    \sgrad H = \left( \bp{p}, -\frac{1}{(q_1^2 + q_2^2)^{\frac{3}{2}}} \bp{q}
    \right).
  \end{equation*}
  The Hamiltonian Differential Equation $\bd{x} = \sgrad H(\bp{x})$ is
  \begin{align*}
    q_1' &= p_1 \qquad p_1' = - \frac{q_1}{(q_1^2 + q_2^2)^{\frac{3}{2}}},\\
    q_2' &= p_2 \qquad p_2' = - \frac{q_2}{(q_1^2 + q_2^2)^{\frac{3}{2}}}.
  \end{align*}
  From here we can recover $\bdd{x} = -\frac{\bp{x}}{|\bp{x}|^3}$.
\end{frame}

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  The vector field $\sgrad f$ has a flow $\phi^t_f$ such that
  \begin{itemize}
  \item $\phi^t_f$ preserves $f$: $f \circ \phi^t_f = f$,
  \item $\phi^t_f$ preserves $\sigma$: $(\phi^t_f)^* \sigma = \sigma$.
  \end{itemize}

  Our proof of Kolmogorov's Theorem will involve the construction of a
  symplectic diffeomorphism $\Phi$ that is a composition of Hamiltonian flows.
\end{frame}

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  We will need to construct Taylor polynomials of functions of the form $t
  \mapsto g \circ \phi^t_f$.

  To do this we use the Poisson bracket.
  \newtheorem{possbrack}{Poisson Bracket}
  \begin{possbrack}
    Let $f$ and $g$ be two functions on $X$.
    The \emph{Poisson bracket}, denoted $\{f, g\}$, is defined by
    \begin{equation*}
      \{f, g\} = \sigma(\sgrad f, \sgrad g) = df(\sgrad g) = - dg(\sgrad f).
    \end{equation*}
  \end{possbrack}
\end{frame}

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  The gradient of the Poisson bracket corresponds to the Lie bracket:
  \begin{equation*}
    \sgrad \{f, g\} = [\sgrad f, \sgrad g].
  \end{equation*}
  Proving this equality is a computation that is not difficult, but rather
  tedious.

  Two function $f$ and $g$ commute if their Poisson bracket is zero: $\{f, g\} =
  0$.

  This implies that their flows commute:
  \begin{equation*}
    \phi_f(s) \circ \phi_g(t) = \phi_g(t) \circ \phi_f(s).
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  In the example involving the Hamiltonian equations of motion, we can write a
  Poisson bracket as
  \begin{equation*}
    \{f, g\} = \sum_{i = 1}^n \left( \pd{f}{q_i} \pd{g}{p_i} - \pd{f}{p_i}
      \pd{g}{q_i}\right).
  \end{equation*}

  The Poisson bracket will allow us to write Taylor polynomials:
  \begin{equation*}
    f \circ \phi^t_g = f + t \{f, g\} + \frac{t^2}{2} \{\{f,g\},g\} +
    \{\{\{f,g\},g\},g\} + \cdots.
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  Denote the torus by $\mathbb{T} = \R / \Z$.
  A \emph{totally integrable system} is a symplectic manifold $X = \mathbb{T}^n
  \times \R^n$ with variables $(\bp{q} \in \mathbb{T}^n, \bp{p} \in \R^n)$,
  symplectic form $\sigma = \sum_i \dif p_i \wedge \dif q_i$, and Hamiltonian
  function $H(\bp{p})$ that depends only on $\bp{p}$.
\end{frame}

\begin{frame}
  \frametitle{Hamiltonian Mechanics}
  The Hamiltionian equations of motion can be integrated.

  The solution with initial value $(\bp{q}_0, \bp{p}_0)$ is
  \begin{align*}
    \bp{q}(t) &= \bp{q}_0 + t \pd{H}{\bp{p}} = \bp{q_0} + t \omega(\bp{p}_0),\\
    \bp{p}(t) &= \bp{p}_0.
  \end{align*}
  In particular, each coordinate $p_1, \ldots, p_n$ is conserved, and the
  trajectory is a linear motion on the torus $\mathbb{T}^n \times \{\bp{p}_0\}$.
\end{frame}

\begin{frame}
  \frametitle{Irrationality}
  We want to make formal the notion of ``suffiently irrational.''
  (Later we will see that this will help us to avoid dividing by zero).  

  A number $\theta$ is irrational if for all pairs $p, q \in \Z$, we have
  $\left|\theta - \frac{p}{q}\right| \neq 0$.

  So for $\theta$ to be ``very'' irrational, we want $\left|\theta -
    \frac{p}{q}\right|$ to be ``very'' different from $0$, or ``very big.''

  But that is not quite possible, as we can always approximate an irrational
  number by rational numbers.
\end{frame}

\begin{frame}
  \frametitle{Irrationality}
  Instead we want to consider what happens with small divisors.

  We want $\left| \theta - \frac{p}{q} \right|$ to be ``small'' \emph{only if}
  the denominator is ``big.''
  % TODO finish
\end{frame}

\begin{frame}
  \frametitle{Irrationality}
  We start with \emph{diophantine conditions}.
  \newtheorem{dionum}{Diophantine of Exponent $d$}
  \begin{dionum}
    \dionumber{}
  \end{dionum}
\end{frame}

\begin{frame}
  \frametitle{Irrationality}
  Note that it is a stronger condition to be Diophantine of a smaller exponent.
  
  \newtheorem{diomany}{Diophantine Numbers with Full Measure}
  \begin{diomany}
    For all $\epsilon > 0$, the set of Diophantine numbers of exponent $2 +
    \epsilon$ is of full measure.
  \end{diomany}
\end{frame}

\begin{frame}
  \frametitle{Irrationality}
  \begin{proof}[Diophantine Numbers with Full Measure]
    Consider numbers in $\R / \Z$.

    For all positive integers $q$, there are at most $q$ elements of $\Q / \Z$
    with denominator $q$ in reduced form.
    Thus for all $\gamma > 0$,
    \begin{equation*}
      \left|\left\{ \theta \in \R / \Z : \left| \theta - \frac{p}{q} \right| <
          \frac{\gamma}{|q|^{2 + \epsilon}} \right\} \right| < 2 \gamma \sum_{q =
      1}^{\infty} \frac{1}{q^{1 + \epsilon}}.
  \end{equation*}
  The intersection of these sets as $\gamma \to 0$ has measure $0$, and this
  intersection is the complement of the set of Diophantine numbers of exponent
  $2 + \epsilon$.
  \end{proof}
\end{frame}

\begin{frame}
  \frametitle{Irrationality}
  We generalize ``sufficiently irrational'' from numbers to vectors.
  \newtheorem{diovec}{Diophantine Vector in $\mathbb{R}^n$}
  \begin{diovec}
    \diovector{}
  \end{diovec}

  We could also rewrite this condition as a dot product
  \begin{equation*}
    |\bp{k} \cdot \omega| \leq \frac{\gamma}{|\bp{k}|^n}.
  \end{equation*}

  In our example of the solar system, the $\omega_i$ represent the
  frequencies of the planets' orbits.
\end{frame}

\begin{frame}
  \frametitle{Irrationality}
  How common are the vectors $\omega$?
  Actually very common, as if we pick components $\omega_i$ at random, we will
  almost surely select such a vector.
  
  \newtheorem{diomeas}{Diophantine Vectors are of Full Measure}
  \begin{diomeas}
    The union $\Omega = \bigcup_{\gamma > 0} \Omega_{\gamma}$ is of full measure.
  \end{diomeas}
\end{frame}

\begin{frame}
  \frametitle{Irrationality}
  \begin{proof}[Diophantine Vectors are of Full Measure]
    Consider $S_{\bp{k}, \gamma}$, the region around the hyperplane orthogonal
    to $\bp{k}$ of thickness $\frac{2\gamma}{|\bp{k}|^{n+1}}$.
    
    The part within the unit cube $Q$ has measure at most
    $\frac{M\gamma}{|\bp{k}|^{n+1}}$, with $M$ the constant giving the max
    $(n-1)$-dim measure of a hyperplane intersected with $Q$.

    The sum $\sum_{\bp{k} \in \Z^n - \{0\}} \frac{1}{|\bp{k}|^{n+1}}$ is finite,
    so the volume of $\bigcup_{\mathclap{\bp{k} \in \Z^n - \{0\}}} S_{\bp{k}, \gamma}
    \cap Q$ is at most a constant times $\gamma$.

    The intersection of these sets has measure $0$, and $\Omega$ is the
    complement, similar to the previous proof.
  \end{proof}
\end{frame}

\begin{frame}
  \frametitle{Torus}
  We view the solar system as an $n$ dimensional torus.

  Give the planets initial positions $\bp{a} = (a_1, \ldots, a_n)$.

  Then the motion $t \mapsto \bp{a} + t \omega = (a_1 + t \omega_1, \ldots, a_n
  + t \omega_n)$ is called a \emph{linear flow on $(\R / \Z)^n$ in the direction
    $\omega$}.

  The trajectory is dense on the torus if and only if the trajectory $\omega$ is
  irrational.

  A motion $\bp{x}(t)$ of a perturbed system is ``the same'' as the motion of an
  unperturbed system $\bp{x}_1(t)$ dense on a torus $T_1$ means that $\bp{x}(t)$
  is dense on a torus $T$ and that there exists a homeomorphism $\Phi : T \to
  T_1$ such that $\Phi(\bp{x}(t)) = \bp{x}_1(t)$.
\end{frame}

\begin{frame}
  \frametitle{Torus}
  \newtheorem{kamsolar}{KAM for the Solar System}
  \begin{kamsolar}
    Let $\bp{x}_1(t)$ be a motion of the zero-masses system for which the
    frequency vector $\omega$ is Diophantine.
    (Then $\bp{x}_1(t)$ is dense on the corresponding torus $T_1$).

    Then there exists $\epsilon > 0$ such that, if the planets have masses $m_i
    < \epsilon$, then there exists a trajectory $\bp{x}(t)$ of the system that
    is dense on a torus $T$, and there exists a homeomorphism $\Phi : T \to T_1$
    such that $\Phi(\bp{x}(t)) = \bp{x}_1(t)$.

    The probability of being on such a trajectory goes to $1$ as $\epsilon$ goes
    to $0$.
  \end{kamsolar}
  % TODO this is what the other article would imply, but I am not sure about
  % the difference between almost periodic and quasiperiodic:
  %This says the solar system is probably almost periodic.
\end{frame}

\begin{frame}
  \frametitle{Another Look at the Theorem}
  \begin{kamthm}
    \KAM{}
  \end{kamthm}
\end{frame}

\begin{frame}
  \frametitle{Analytic Functions}

  We will be solving a system of equations iteratively, using an analog of
  Newton's method.
  
  Newton's method for solving an equation $f(\bp{x}) = 0$ consists of choosing a
  starting guess $\bp{x}_0$ and then defining
  \begin{equation*}
    \bp{x}_{i+1} = \bp{x}_i - [Df(\bp{x}_i)]^{-1} f(\bp{x}_i).
  \end{equation*}

  But we might pick a ``bad'' initial guess for which Newton's method does not
  converge to a solution.

  For example, taking $f(x) = x^3 - x + \frac{\sqrt{2}}{2}$ and the initial
  guess $x_0 = 0$, Newton's method will oscillate between $0$ and
  $\frac{\sqrt{2}}{2}$.
\end{frame}

\begin{frame}
  \frametitle{Analytic Functions}
  In order to guarantee convergence, we use Kantorovich's theorem.

  This theorem requires a bound on the second derivative.

  We want an analogous condition for our problem.
\end{frame}

\begin{frame}
  \frametitle{Analytic Functions}
  We need a way to measure ``size,'' that is, we need to choose a norm for our
  functions.

  Let $X \subseteq \C^k$ be compact.
  \footnote{ Or as Alex might like to say, let $X$ be a compact.}

  Let the caligraphic letter $\mathcal{X}$ be the Banach algebra of continuous
  functions on $X$ that are analytic in the interior and have the sup norm
  \begin{equation*}
    \norm{f}_X = \sum_{\bp{x} \in X} |f(\bp{x})|.
  \end{equation*}

  We use the absolute value as the standard Euclidean norm on $\C^n$.
\end{frame}

\begin{frame}
  \frametitle{Analytic Functions}
  We consider three regions:
  \domains{}

  Denote by $\mathcal{B}_\rho$, $\mathcal{C}_\rho$, and $\mathcal{A}_\rho$ the
  corresponding Banach algebras.

  We can expand elements of $\mathcal{B}_{\rho}$ as power series, and elements of
  $\mathcal{C}_{\rho}$ as Fourier series:
  \begin{equation*}
    f(\bp{z}) = \sum_{\bp{k} \in \Z^n} f_{\bp{k}} e^{2 \pi i \, \bp{k} \cdot \bp{z}}.
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{Analytic Functions}
  We can bound derivatives of analytic functions on balls in terms of the values
  of the function itself.
  \newtheorem{cauchyball}{Cauchy's Inequalities on Balls}
  \begin{cauchyball}
    If $f \in \mathcal{B}_{\rho}$, then
    \begin{align*}
      \norm{Df}_{\rho - \delta} &\leq \frac{1}{\delta} \norm{f}_{\rho},\\
      \norm{D^2 f}_{\rho - \delta} &\leq \frac{4}{\delta^2} \norm{f}_{\rho}.
    \end{align*}

    As a corollary, the case $\delta = \rho$ bounds derivatives at the center of
    balls.
    \begin{align*}
      |Df(0)| &\leq \frac{1}{\rho} \norm{f}_{\rho},\\
      |D^2 f(0)| &\leq \frac{4}{\rho^2} \norm{f}_{\rho}.
    \end{align*}
  \end{cauchyball}
\end{frame}

\begin{frame}
  \frametitle{Analytic Functions}
  \begin{proof}[Cauchy's Inequalities on Balls]
    Take $\bp{z} \in B_{\rho - \delta}$ and $\bp{u} \in \C^n$.
    Since $B_{\delta}(\bp{z}) \subseteq B_{\rho}$, the function $g : t \mapsto
    f(\bp{z} + t \delta \bp{u})$ is defined on the unit disc, and the normal
    Cauchy inequality implies that
    \begin{equation*}
      \delta|(Df(\bp{z}))\bp{u}| = |g'(0)| \leq \norm{g}_1 \leq
      \norm{f}_{\rho}.
    \end{equation*}
    Applying the argument twice gives the result for the second derivative:
    \begin{equation*}
      |D^2 f(\bp{z})(\bp{u}, \bp{v})| \leq \frac{2}{\delta}
      \norm{Df(\bp{z})(\bp{u})}_{\rho - \frac{\delta}{2}}|\bp{v}| \leq
      \frac{4}{\delta^2} \norm{f}_{\rho} |\bp{u}||\bp{v}|.
    \end{equation*}
  \end{proof}
\end{frame}

\begin{frame}
  \frametitle{Smell of the Proof}
  Recall the final equation in Kolmogorov's theorem:
  \begin{equation*}
    H(\bp{Q}, \bp{P}) = A + \omega \bp{P} + R (\bp{Q}, \bp{P}).
  \end{equation*}
  This is an equation for a diffeomorphism $\Phi$.
  We solve for this diffeomorphism.
  To do so we would like to use Newton's method, but using it is not quite
  sufficient.
  However we can still do something with a similar flavor.

  We obtain $\Phi$ as a limit of $\Phi_i$, where
  \begin{equation*}
    \Phi_i = \phi_i \circ \phi_{i-1} \circ \cdots \circ \phi_1.
  \end{equation*}
  Here, $\phi_i$ is the Hamiltonian flow for a Hamiltonian function $g_i$.
  This $g_i$ is the unknown for which we solve.
\end{frame}

\begin{frame}
  \frametitle{Smell of the Proof}
  At the $i$th step we have a Hamiltonian $\tilde{h} = \Phi_i^* h$.

  We expand $\tilde{h}$ up to order $2$ in $\bp{p}$, and the coefficients will
  be Fourier series in $\bp{q}$.

  We write $\tilde{h} = \tilde{h}_0 + \tilde{h}_1$:
  \begin{itemize}
  \item $\tilde{h}_1$ has the terms constant or linear in $\bp{p}$, except the
    constant in $\bp{q}$,
  \item $\tilde{h}_0$ is everything else.
  \end{itemize}
 
  We would like to eliminate $\tilde{h}_1$, but we won't be able to do so by
  solving a linear equation.

  Instead we will solve a linear equation for a function $g$ such that $\phi^*_g
  \tilde{h}$ is ``better'' than $\tilde{h}$, in some reasonable sense of
  ``better.''
\end{frame}

\begin{frame}
  \frametitle{Smell of the Proof}
  We expand $\phi^*_g \tilde{h}$ to first order in $g$:
  \begin{align*}
    \phi^*_g \tilde{h} &= \tilde{h} + \{g, \tilde{h}\} + o(|g|)\\
    &= \tilde{h}_0 + \tilde{h}_1 + \{g, \tilde{h}_0\} + \{g, \tilde{h}_1\} +
      o(|g|).
  \end{align*}
  We want to eliminate the terms, other than the term constant in $\bp{q}$, that
  are not $O(|\bp{p}|)^2$.

  Applying the standard Newton's method would necessitate solving the equation
  \begin{equation*}
    \tilde{h}_1 + \{g, \tilde{h}_0\} + \{g, \tilde{h}_1\} \in o(|\bp{p}|).
  \end{equation*}

  But we will do something a bit different.
\end{frame}

\begin{frame}
  \frametitle{Smell of the Proof}
  We can assume that anything we want is small as long as the choice is
  justified by the resulting inequalities.

  So suppose that $\{g, \tilde{h}_1\}$ is of order $2$ since $g$ and
  $\tilde{h}_1$ are both small.

  Then the linear equation that we need to solve is
  \begin{equation*}
    \tilde{h}_1 + \{g, \tilde{h_0}\} \in o(|\bp{p}|).
  \end{equation*}

  This is a \emph{Diophantine differential equation}, and our ability to solve
  it will rely on the Diophantine vectors that we saw previously.
\end{frame}

\begin{frame}
  \frametitle{Diophantine Differential Equations}
  Let $g \in \mathcal{C}_\rho$.
  We are going to be solving linear equations of the form
  \begin{equation*}
    \Dif f(\omega) = \sum_{i = 1}^n \omega_i \pd{f}{q_i} = g,
  \end{equation*}
  with $f \in \mathcal{C}_{\rho'}$ for some $\rho' < \rho$.

  Write the functions $f$ and $g$ as Fourier Series:
  \begin{align*}
    f(\bp{q}) &= \sum_{\bp{k} \in \Z^n} f_{\bp{k}} e^{2 \pi i \, \bp{k} \cdot
      \bp{q}},\qquad g(\bp{q}) = \sum_{\bp{k} \in \Z^n} g_{\bp{k}} e^{2 \pi i \,
                \bp{k} \cdot \bp{q}}.
  \end{align*}
  The solution is given by
  \begin{equation*}
    f_{\bp{k}} = \frac{1}{2 \pi i \, (\bp{k} \cdot \omega)} g_{\bp{k}}.
  \end{equation*}
  We need $g_0$ to be zero.
  Then $f_0$ is arbitrary, and otherwise the series for $f$ is unique.
\end{frame}

\begin{frame}
  \frametitle{Diophantine Differential Equations}
  The convergence properties of $f$ depend on the Diophantine properties of
  $\omega$.

  We cannot divide by zero when computing the Fourier coefficients $f_{\bp{k}}$.
  
  Even though we have convergence for $\rho$, we might not have boundedness.
  So we need some $\rho' < \rho$ where we have boundedness, but large enough so
  that the limit is nonempty.
\end{frame}

\begin{frame}
  \frametitle{Diophantine Differential Equations}
  We will use the following tool for choosing $\rho'$.
  \newtheorem{pickrho}{Proposition}
  \begin{pickrho}
    If $g \in \mathcal{C}_{\rho}$ and $\omega \in \Omega_{\gamma}$, then for all
    $\delta \in (0, \rho)$ we have
    \begin{align*}
      \norm{f}_{\rho - \delta} &\leq \frac{\kappa_n}{\gamma \delta^{2n}}
               \norm{g}_{\rho},\\
      \norm{Df}_{\rho - \delta} &\leq \frac{\kappa_n}{\gamma \delta^{2n+1}}
                \norm{g}_{\rho},\\
    \end{align*}
    where $\kappa_n$ is a constant that depends only on $n$.
  \end{pickrho}
  Next we will prove this proposition.
\end{frame}

\begin{frame}
  \frametitle{Diophantine Differential Equations}
  For $\bp{y} \in \R^n$ with $|\bp{y}| \leq \rho$ (in particular $\bp{y} =
  \rho\frac{\bp{k}}{|\bp{k}|}$), the function $\bp{q} \mapsto
  g(\bp{q} - i \bp{y})$ is continuous and periodic in $\bp{q}$ of period $1$.

  This function can be written
  \begin{equation*}
    g(\bp{q} - i \bp{y}) = \sum_{\bp{k} \in \Z^n} g_{\bp{k}}e^{2 \pi i \bp{k}
      \cdot (\bp{q} - i \bp{y})} = \sum_{\bp{k} \in \Z^n} \left( g_{\bp{k}} e^{2
      \pi \bp{k} \cdot \bp{y}} \right) e^{2 \pi i \bp{k} \cdot \bp{q}}.
  \end{equation*}

  By Parseval's theorem, we have
  \begin{equation*}
    \norm{g}_{\rho}^2 \geq \int_{\mathbb{T}^n} |g(\bp{q} - i \bp{y})|^2 |d^n
    \bp{q}| = \sum_{\bp{k} \in \Z^n} |g_{\bp{k}}|^2 e^{4 \pi \bp{k} \cdot \bp{y}}.
  \end{equation*}

  Since the series has positive numbers, we have
  \begin{equation*}
    \norm{g}_{\rho}^2 \geq |g_{\bp{k}}|^2 e^{4 \pi \rho |\bp{k}|}.
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{Diophantine Differential Equations}
  Using the Diophantine-ness of $\omega$ and the Fourier coefficients
  $f_{\bp{k}}$, we have
  \begin{equation*}
    |f_{\bp{k}}| \leq \frac{1}{2 \pi \gamma} \norm{g}_{\rho} |\bp{k}|^n e^{-2
      \pi |\bp{k}| \rho}.
  \end{equation*}

  Next we split the proposition's proof into two parts: the $f$ case and the
  $Df$ case.
\end{frame}

\begin{frame}
  \frametitle{Diophantine Differential Equations}
  For $|\bp{q}| \leq \rho - \delta$, we can write
  \begin{align*}
    \left| f_{\bp{k}}e^{2 \pi i (\bp{k} \cdot \bp{q})} \right|
    & \leq \sum_{\bp{k} \in \Z^n} \frac{|\bp{k}|^n}{2 \pi \gamma}
      \norm{g}_{\rho} e^{-2 \pi \rho |\bp{k}|(\rho - \delta)}\\
    &= \frac{\norm{g}_{\rho}}{2 \pi \gamma} \sum_{\bp{k} \in \Z^n} |\bp{k}|^n
      e^{-2 \pi |\bp{k}| \delta}.
  \end{align*}

  We then rewrite the sum on the right:
  \begin{equation*}
     \sum_{\bp{k} \in \Z^n} |\bp{k}|^n
       e^{-2 \pi |\bp{k}| \delta} = \frac{1}{(2 \pi \delta)^{2n}} \left( (2 \pi
        \delta)^n \sum_{\bp{k}' \in 2 \pi \delta \Z^n} |\bp{k}'|^n
       e^{-|\bp{k}'|}\right).
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{Diophantine Differential Equations}
  \begin{equation*}
     \sum_{\bp{k} \in \Z^n} |\bp{k}|^n
      e^{-2 \pi |\bp{k}| \delta} = \frac{1}{(2 \pi \delta)^{2n}} \left( (2 \pi
        \delta)^n \sum_{\bp{k}' \in 2 \pi \delta \Z^n} |\bp{k}'|^n
        e^{-|\bp{k}'|}\right).
  \end{equation*}
  As $\delta \to 0$, the expression inside the parentheses approaches
  $\int_{\R^n} |\bp{x}|^n e^{-|\bp{x}|} |d^n\bp{x}|$.

  Since the interval is convergent there exists $\kappa_n'$ such that for
  $\delta \leq 1$, it holds that
  \begin{equation*}
    \sum_{\bp{k} \in \Z^n} |\bp{k}|^n e^{-2 \pi |\bp{k}| \delta} \leq
    \frac{\kappa_n'}{(2 \pi \delta)^{2n}}.
  \end{equation*}
  This is the ``$f$'' part of the proof.
\end{frame}

\begin{frame}
  \frametitle{Diophantine Differential Equations}
  The ``$Df$'' part of the proof is similar.
  
  Use
  \begin{equation*}
    Df(\bp{q})(\bp{u}) = 2 \pi i \sum (\bp{k} \cdot \bp{u}) f_{\bp{k}} e^{2 \pi
      i (\bp{k} \cdot \bp{q})}.
  \end{equation*}

  We obtain
  \begin{equation*}
    |Df(\bp{q})(\bp{u})| \leq \frac{|\bp{u}| \norm{g}_{\rho} \kappa_n''}{\gamma
      (2 \pi \gamma)^{n+1}}.
  \end{equation*}

  To complete the proof of the proposition, take
  \begin{equation*}
    \kappa_n = \max \left\{ \frac{\kappa_n'}{(2 \pi)^{2n}},
      \frac{\kappa_n''}{(2\pi)^{2n + 1}} \right\}.
  \end{equation*}
\end{frame}

\begin{frame}
  \frametitle{The Equations to Solve}
  Let's return to $h_1 + \{g, h_0\} \in O(|\bp{p}|^2)$ (the Diophantine differential
  equation that we had before, but without the tildes and with $o(|\bp{p}|)$
  replaced by $O(|\bp{p}|^2)$, which is equivalent since our functions are
  analytic).

  The unknown is $g$, which we take to be degree $1$ in $\bp{p}$:
  \begin{equation*}
    g = \lambda \bp{q} + X(\bp{q}) + \sum_{i = 1}^n Y_i(\bp{q}) p_i
  \end{equation*}
  Note that only the linear terms of $g$ contribute to the linear terms of $\{g,
  h_0\}$.

  The unknowns are: $\lambda$, $X$, $Y_i$.

  We can expand $X$ and $Y_i$ as Fourier series, since they are functions of
  $\bp{q}$ only.
\end{frame}

\begin{frame}
  \frametitle{The Equations to Solve}
  Let $a \in \R$, $\omega \in \Omega_{\gamma}$,
  $R(\bp{q}, \bp{p}) \in O(|\bp{p}|^3)$, and $\overline{A} = 0$ be the average
  of $A$ on the torus $\bp{p} = 0$, we can write
  \begin{align*}
    h_0(\bp{q}, \bp{p}) &= a + \omega \bp{p} + \frac{1}{2} \bp{p} \cdot
                          C(\bp{q}) \bp{p} + R(\bp{q}, \bp{p}),\\
    h_1(\bp{q}, \bp{p}) &= A(\bp{q}) + B(\bp{q}) \bp{p}.
  \end{align*}
  We then have
  \begin{align*}
    (h_1 + &\{g, h_0\}) (\bp{q}, \bp{p})\\
           &= \omega \cdot \lambda + A(\bp{q}) + DX(\bp{q})(\omega)\\
           &\qquad + \Big(B(\bp{q}) + \big( \lambda + DX(\bp{q}) \big) C(\bp{q}) +
             \omega DY(\bp{q}) \Big) \cdot \bp{p} + O(|\bp{p}|^2).
  \end{align*}

\end{frame}

\begin{frame}
  \frametitle{The Equations to Solve}
  We need to solve the equations
  \begin{align*}
    DX(\bp{q})(\omega) &= -A(\bp{q})\\
    DY(\bp{q})(\omega) &= -B(\bp{q}) - \big( \lambda + DX(\bp{q}) \big)
                C(\bp{q})
  \end{align*}
  for $X$ and $Y_i$, $i = 1, \ldots, n$.

  These are Diophantine differential equations.

  Since we have the hypothesis $\overline{A} = 0$, we can solve the first
  equation and find $X \in \mathcal{C}_{\rho'}$ for all $\rho' < \rho$.

  We then substitute into the second equation.
\end{frame}

\begin{frame}
  \frametitle{The Equations to Solve}
  We need to solve the equations
  \begin{align*}
    DX(\bp{q})(\omega) &= -A(\bp{q})\\
    DY(\bp{q})(\omega) &= -B(\bp{q}) - \big( \lambda + DX(\bp{q}) \big)
                C(\bp{q})
  \end{align*}
  for $X$ and $Y_i$, $i = 1, \ldots, n$.

  We can then determine $\lambda$ since the averages of the right-hand sides in
  the $n$ are all zero.

  Then we can solve the second equation and find $Y_i \in \mathcal{C}_{\rho''}$
  for all $\rho'' < \rho'$.
  
  Iterating the process requires choosing $\rho'$ and $\rho''$ ``carefully.''
\end{frame}


\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
